---
title: "Telematics Combined Actuarial Neural Networks for claim count data"
subtitle: "Co-operators show and share"
author: "Francis Duval"
institute: "Université du Québec à Montréal"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    seal: false
    css: "theme_cara.css"
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: title-slide
background-image: url(images/logo_chaire.jpg), url(images/background.jpg)
background-size: 30%, cover
background-position: 98% 98%, center

.titre-page-titre[Telematics Combined Actuarial Neural Networks for Claim Count Data]
<br />
.sous-titre-page-titre[Co-operators Show and Share]
<br />
<br />
***
<br />
<br />
.sous-sous-titre-page-titre[.mon-style-bleu[par] Francis Duval <br> .mon-style-bleu[à] l'Université du Québec à Montréal <br> .mon-style-bleu[le] 17 mai 2023]

---

# Introduction

.left-column[
```{r echo = F, out.width = "60%", fig.align = "center"}
knitr::include_graphics("images/tele_icon.png")
```

```{r echo = F, out.width = "65%", fig.align = "center"}
knitr::include_graphics("images/brain_icon.png")
```

```{r echo = F, out.width = "60%", fig.align = "center"}
knitr::include_graphics("images/nn_icon.png")
```
]

.right-column[
<br>
<br>
<br>
.ecriture-grise[For several years now, insurers have been using telematics information in their pricing models.]
<br>
<br>
<br>
.ecriture-grise[Most of the time, human brainpower is used to extract features from raw data that are thought to be correlated with claiming risk.]
<br>
<br>
<br>
.ecriture-grise[What if we automated this feature engineering process with a neural network?]
]

---

# Introduction
<div class="neg-break"></div>
## Combined Actuarial Neural Network (CANN) approach
<div class="neg-break"></div>
.pull-left[
```{r echo = F, out.width = "90%", fig.align = "center"}
knitr::include_graphics("images/CANN.png")
```

.center[Figure taken from [this paper](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID3320525_code769240.pdf?abstractid=3320525)
]].
</br>
</br>
</br>
.ecriture-grise[Consists of a .bleu-gras[classical parametric model] (often a GLM) to which a .bleu-gras[neural network] has been attached.]

.ecriture-grise[The goal of the neural network part is to .bleu-gras[capture] any .bleu-gras[signal] that might have been missed by the GLM.]

.ecriture-grise[Parameters for the GLM part are typically initialized at .bleu-gras[maximum likelihood], while those of the neural network part are initialized to .bleu-gras[zero].]

---

background-image: url(images/perceptron.png)
background-size: 75%
background-position: 100% 70%

# GLM as a neural network

.ecriture-grise[Equivalence table]
.left-column[
| Perceptron | GLM |
|--------|-----------|
| Bias $w_0$ | $\beta_0$ |
| Weights $w_1, \dots, w_m$ | $\beta_1, \dots, \beta_p$ |
| Activation function $g$ | Inverse link function $g^{-1}$ |
]

---

# Data

## Traditional rating factors 
<div style="margin-top: -70px; margin-left: -130px; margin-bottom: 20px;" class="layer">
  <div class="neuron gris"></div>
  <div class="neuron gris"></div>
  <div class="neuron gris"></div>
</div>

<!-- <div style="margin-top: -60px; margin-left: 450px; margin-bottom: 40px;" class="neuron gris"></div> -->


| Name                | Description                                              | Type        |
|---------------------|----------------------------------------------------------|-------------|
| `annual_distance`   | Annual distance declared by the insured                  | Numeric     |
| `commute_distance`  | Distance to the place of work declared by the insured    | Numeric     |
| `conv_count_3_yrs_minor` | Number of minor contraventions in the last 3 years  | Numeric     |
| `gender`            | Gender of the insured                                    | Categorical |
| `marital_status`    | Marital status of the insured                            | Categorical |
| `pmt_plan`          | Payment plan chosen by the insured                       | Categorical |
| `veh_age`           | Vehicle age                                              | Numeric     |
| `veh_use`           | Use of the vehicle                                       | Categorical |
| `years_claim_free`  | Number of years since last claim                         | Numeric     |
| `years_licensed`    | Number of years since obtaining driver's license         | Numeric     |
| `distance`          | Real distance driven                                     | Numeric     |

---

# Data

## Extract from the telematics dataset

| Contract ID | Trip ID | Departure datetime | Arrival datetime | Distance | Maximum speed |
|:-----------:|:------:|:-----------------:|:----------------:|:--------:|:-------------:|
| A | 1 | 2017-05-02 19:04:15 | 2017-05-02 19:24:24 | 25.0 | 104 |
| A | 2 | 2017-05-02 21:31:29 | 2017-05-02 21:31:29 | 6.4 | 66 |
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
| A | 2320 | 2018-04-30 21:17:22 | 2018-04-30 21:18:44 | 0.2 | 27 |
| B | 1 | 2017-03-26 11:46:07 | 2017-03-26 11:53:29 | 1.5 | 76 |
| B | 2 | 2017-03-26 15:18:23 | 2017-03-26 15:51:46 | 35.1 | 119 |
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
| B | 1485 | 2018-03-23 20:07:08 | 2018-03-23 20:20:30 | 10.1 | 92 |
| C | 1 | 2017-11-20 08:14:34 | 2017-11-20 08:40:21 | 9.7 | 78 |
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |

---

# Data

<div style="margin-top: -30px;"></div>

## Telematics inputs

<div style="margin-top: -70px; margin-left: -370px; margin-bottom: 20px;" class="layer">
  <div class="neuron vert"></div>
  <div class="neuron vert"></div>
  <div class="neuron vert"></div>
</div>

.ecriture-grise[We want the neural network to learn features from the telematics dataset, but we still need a minimal preprocesssing.]

<div style="margin-top: -5px;"></div>
.ecriture-grise[We thus define the following vectors:]

.bloc.bleu[
$\boldsymbol{h} = (h_1, h_2, \dots, h_{24})$ where $h_i$ is the fraction of driving in the $i^\text{th}$ hour of the day.

$\boldsymbol{p} = (p_1, p_2, \dots, p_7)$ where $p_i$ is the fraction of driving in the $i^\text{th}$ day of the week.

$\boldsymbol{vmo} = (vmo_1, vmo_2, \dots, vmo_{14})$ where $vmo_i$ is the fraction of trips in the $i^\text{th}$ interval of average speed.

$\boldsymbol{vma} = (vma_1, vma_2, \dots, vma_{16})$ where $vma_i$ is the fraction of trips in the $i^\text{th}$ interval of maximum speed.
]

.ecriture-grise[We then concatenate these 4 vectors into a big input vector of dimension 24 + 7 + 14 + 16 = 61, which will be given as input to the MLP part of the CANN model:]

$\textbf{telematics_input_vec} = (\boldsymbol{h}, \boldsymbol{p}, \boldsymbol{vmo}, \boldsymbol{vma})$

---
$$\newcommand{\Xcal}{\mathcal{X}}$$
# Poisson regression

<div style="margin-top: -60px;"></div>
**Assumptions:**
- Given its predictors $\boldsymbol{x}_i$, the PMF of $Y_i$, the number of claims for contract $i$, is given by:
\begin{align}
P(Y_i = y_i) = \frac{e^{-\mu(\boldsymbol{x_i})}\mu(\boldsymbol{x_i})^{y_i}}{y_i!}, \quad y_i = 0, 1, \dots,
\end{align}
with
\begin{align}
\mathbb{E}(Y_i) = \text{Var}(Y_i) = \mu(\boldsymbol{x_i})
\end{align}

**Goal:**
- Find a good regression function $\mu: \Xcal \rightarrow \mathbb{R}^+$ mapping the predictors $\boldsymbol{x}$ to the parameter $\mu$.

**How to proceed:**
- Choose a specification for the regression function $\mu(\cdot)$ 
- Minimise the negative log-likelihood over the training set:
\begin{align}
\underset{\mu}{\text{minimize}} \left\{ -\frac{1}{n} \sum_{i \in \mathcal{T}} y_i \ln\left[\mu(\boldsymbol{x_i})\right] - \mu(\boldsymbol{x}_i)\right\}
\end{align}

---

background-image: url(images/PoissonCANN.png)
background-size: 60%
background-position: 80% 80%

# Poisson CANN

.pull-left[
```{r echo = F, out.width = "60%", fig.align = "left"}
knitr::include_graphics("images/PoissonCANN_legend.png")
```
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
- The output $\mu$ is compared with the response $y$ to compute the negative log-likelihood.
]

---

$$\newcommand{\Xcal}{\mathcal{X}}$$
# Negative binomial regression

**Assumptions:**
- Given its predictors $\boldsymbol{x}_i$, the PMF of $Y_i$, the number of claims for contract $i$, is given by:
\begin{align}
P(Y_i = y_i) = \frac{\Gamma(y_i + \phi)}{y_i! \Gamma(\phi)} \left(\frac{\phi}{\phi + \mu(\boldsymbol{x}_i)}\right)^\phi \left( \frac{\mu(\boldsymbol{x}_i)}{\mu(\boldsymbol{x}_i) + \phi}\right)^{y_i}, \quad y_i = 0, 1, \dots,
\end{align}
with
\begin{align}
\mathbb{E}(Y_i) = \mu(\boldsymbol{x}_i) \quad \text{and} \quad \text{Var}(Y_i) = \mu(\boldsymbol{x}_i) + \frac{\mu(\boldsymbol{x}_i)^2}{\phi}
\end{align}

**How to proceed**:

- We seek for a good regression function $\mu: \Xcal \rightarrow \mathbb{R}^+$ mapping the predictors $\boldsymbol{x}$ to the parameter $\mu$ and a good estimate of $\phi$.
- Again, we proceed by minimising the negative log-likelihood.
- With this specification, we will need a 2-output neural network

---

background-image: url(images/NB2CANN.png)
background-size: 60%
background-position: 80% 80%

# Negative binomial CANN

.pull-left[
```{r echo = F, out.width = "60%", fig.align = "left"}
knitr::include_graphics("images/PoissonCANN_legend.png")
```
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
- The outputs $\mu$ and $\phi$ are compared with the response $y$ to compute the negative log-likelihood.
]

